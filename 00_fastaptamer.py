# -*- coding: utf-8 -*-
"""00-fastaptamer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x2emx0Gy_RBciOP7OIGhuwWq_qqkQqHP

### install sratoolkit
1. download from NCBI: [SRA Toolkit](https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz)

2. unzip the file
3. install sratoolkit
"""

!wget --output-document sratoolkit.tar.gz https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz

!tar -vxzf sratoolkit.tar.gz

!which fastq-dump

!sudo apt install sra-toolkit

# !fastq-dump --stdout -X 2 SRR12960220
# !prefetch SRR12960220
# !ls /content/SRR12960220
# !fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip /content/SRR12960220/SRR12960220.sra

"""### download the SRR file
1-prefetch

2-unzip fastq files to fastq folders
"""

import subprocess

# samples correspond to round1_low_negative, round1_low_positive
sra_numbers = [
    "SRR12960220", "SRR12960218"
    ]

# this will download the .sra files to ~/ncbi/public/sra/ (will create directory if not present)
for sra_id in sra_numbers:
    print ("Currently downloading: " + sra_id)
    prefetch = "prefetch " + sra_id
    print ("The command used was: " + prefetch)
    subprocess.call(prefetch, shell=True)

# this will extract the .sra files from above into a folder named 'fastq'
for sra_id in sra_numbers:
    print ("Generating fastq for: " + sra_id)
    fastq_dump = "fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip /content/"+ sra_id +"/" + sra_id + ".sra"
    print ("The command used was: " + fastq_dump)
    subprocess.call(fastq_dump, shell=True)

for sra_id in sra_numbers:
  print(f"Unzip fastq file of {sra_id} in fastq folder")
  fastq_unzip = "gzip -dk /content/fastq/" + sra_id + "_pass_1.fastq.gz"
  subprocess.call(fastq_unzip, shell=True)

# !gzip -dk /content/fastq/SRR12960220_pass_1.fastq.gz
# /content/fastq/SRR12960220_pass_1.fastq.gz

"""### Changing fastq to fasta

1- granting exeucatable to fastaptamer_count file

"""

#fastaptamer_count_dir = "/content/drive/MyDrive/BioProj/FastaProj/fastaptamer_count"

!chmod +x /content/drive/MyDrive/BioProj/FastaProj/fastaptamer_count

for sra_id in sra_numbers:
  print(f"changing fastq file of {sra_id} to fasta file")
  fastq_to_fasta = f"/content/drive/MyDrive/BioProj/FastaProj/fastaptamer_count " \
                 f"-i/content/fastq/{sra_id}_pass_1.fastq -o /content/fastq/{sra_id}.fasta"
  subprocess.call(fastq_to_fasta, shell=True)

# ! /content/drive/MyDrive/BioProj/FastaProj/fastaptamer_count -i /content/fastq/SRR12960220_pass_1.fastq -o /content/fastq/SRR12960220_pass_1.fasta

"""### install Biopython

import pandas, make the list by fasta files

"""

!pip install Biopython
from Bio import SeqIO
import pandas as pd

for sra_id in sra_numbers:
  if sra_id == "SRR12960218":
    seq_objects_positive = SeqIO.parse(f"/content/fastq/{sra_id}.fasta",'fasta')
    seq_round1_low_positive=[]
    ids_round1_low_positive=[]
    for record in seq_objects_positive:
      seq_round1_low_positive.append(str(record.seq))
      ids_round1_low_positive.append(record.id)
  else:
    seq_objects_negative = SeqIO.parse(f"/content/fastq/{sra_id}.fasta",'fasta')
    seq_round1_low_negative=[]
    ids_round1_low_negative=[]
    for record in seq_objects_negative:
      seq_round1_low_negative.append(str(record.seq))
      ids_round1_low_negative.append(record.id)

"""
## here i wrote the code, cell after i should revise and update

https://medium.com/tensorflow/using-nucleus-and-tensorflow-for-dna-sequencing-error-correction-47f3f7fc1a50"""

len(sequences)

ranks = []
reads = []
rpms = []

for item in ids:
  values = item.split("-")

  rank = int(values[0])
  read = int(values[1])
  rpm = float(values[2])

  ranks.append(rank)
  reads.append(read)
  rpms.append(rpm)

count_1 = pd.DataFrame({'Sequence': sequences, 'ID': ids})
count_2 = pd.DataFrame({'Rank': ranks, 'Read': reads, 'RPM':rpms, 'Sequence': sequences})

count_2.head()





import matplotlib.pyplot as plt
from matplotlib import ticker
import plotly.express as px
import plotly.graph_objects as go
import os

import imblearn
import random

# reading file

import zipfile

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip

zip_ref = zipfile.ZipFile("10_food_classes_10_percent.zip")
zip_ref.extractall()
zip_ref.close()

# or
unzip_data("xxx.zip")

# One_hot encoding
# https://www.kaggle.com/code/zakarii/dna-sequence-classification-cnn-gru?scriptVersionId=60362406&cellId=13

def encode_seq(s):
    Encode = {'A':[1,0,0,0],'T':[0,1,0,0],'C':[0,0,1,0],'G':[0,0,0,1]}
    return [Encode[x] for x in s]

for i in sequence:
    x = encode_seq(i)
    encoded_list.append(x)

X = np.array(encoded_list)
X.shape

class FeedForwardTrainer:
  """Class for training a simple feedforward net on aptamers data.

  This class constructs the TF graph we need to train a model on aptamer data
  and to evaluate the model on the validation data during training. It also
  provides a method to actually run the training and uses some helper methods
  to handle reporting training progress.

  During training, this class also measures validation error. Therefore it also
  builds the graph needed for making predictions on new data using feed_dict.
  To evaluate the model, we feed serialized example protos to self.val_strs.

  Attributes:
    hps: The configuration object holding values of training metaparameters.
      The trainer object just expects hps to have a learn_rate and momentum
      attribute, but if the network uses the same object more attributes are
      needed. Usually we expect hps to be an instance of tf.HParams and in
      order for restoring the model to work it will need to be.
    experiment_proto: selection_pb2.Experiment describing the experiment.
    net: The neural net we are training.
    train_dir: The folder we write checkpoints and other data to.
    global_step: TF variable holding the global step counter
  """

def __init__(self, hps, net, output_layer, experiment_proto, input_paths):
    inputs, outputs = data.input_pipeline(
        input_paths, experiment_proto, hps.mbsz, hps=hps, num_threads=8)
    with tf.name_scope('neural_net'):
      logits = net.fprop(inputs, mode='train')
    with tf.name_scope('output_layer'):
      loss_per_target = output_layer.average_loss_per_target(
          logits, outputs, include_array=hps.train_on_array)
      loss = utils.reduce_nanmean(loss_per_target)

    self.global_step = tf.Variable(0, name='global_step', trainable=False)
    if hps.optimizer == 'momentum':
      optimizer = tf.MomentumOptimizer(hps.learn_rate, hps.momentum)
    elif hps.optimizer == 'adam':
      optimizer = tf.AdamOptimizer(hps.learn_rate)
    else:
      raise ValueError('invalid optimizer: %s' % hps.optimizer)
    optimizer = tf.MomentumOptimizer(hps.learn_rate, hps.momentum)
    grads = optimizer.compute_gradients(loss, net.params + output_layer.params)
    opt_op = optimizer.apply_gradients(grads, global_step=self.global_step)
    self.train_op = tf.with_dependencies([opt_op], loss)

    contrib_deprecated.scalar_summary('loss/mean', loss)
    for target in loss_per_target.axes['target'].labels:
      contrib_deprecated.scalar_summary(
          'loss/' + six.ensure_str(target),
          lt.select(loss_per_target, {'target': target}))
    with tf.name_scope('summarize_grads'):
      slim.learning.add_gradients_summaries(grads)

    tf.add_to_collection(tf.GraphKeys.GLOBAL_STEP, self.global_step)
    tf.add_to_collection('train_op', self.train_op)
    tf.add_to_collection('loss', loss)

    self.mbsz = hps.mbsz
    # The log Poisson loss implemented in TensorFlow may sometimes be negative.
    if (hps.loss_name == output_layers.LOSS_POISSON_LOSS or
        hps.loss_name == output_layers.LOSS_ZERO_TRUNCATED_POISSON_LOSS):
      self.min_cost = -float('inf')
      self.min_is_inclusive = False
    else:
      self.min_cost = 0
      self.min_is_inclusive = True



def run_training(hps,
                 experiment_proto,
                 train_dir,
                 train_input_paths,
                 val_input_paths,
                 tuner=None,
                 master='',
                 metrics_targets=None,
                 metrics_measures=None):
  """Main training function.

  Trains the model given a directory to write to and a logfile to write to.

  Args:
    hps: tf.HParams with training parameters.
    experiment_proto: selection_pb2.Experiment proto for training.
    train_dir: str path to train directory.
    train_input_paths: List[str] giving paths to input sstables for training.
    val_input_paths: List[str] giving paths to input sstable(s) for validation.
    tuner: optional hp_tuner.HPTuner.
    master: optional string to pass to a tf.Supervisor.
    metrics_targets: String list of network targets to report metrics for.
    metrics_measures: Measurements about the performance of the network to
        report, e.g. 'auc/top_1p'.

  Returns:
    None.

  Raises:
    Error: if the hyperparamter combination in hps is infeasible and there is
    no tuner. (If the hyperparameter combination is infeasible and there is
    a tuner then the params are reported back to the tuner as infeasible.)
  """
  hps_infeasible, infeasible_reason = hps_is_infeasible(
      hps, experiment_proto.sequence_length)
  if hps_infeasible:
    if tuner:
      tuner.report_done(True, infeasible_reason)
      logger.info('report_done(infeasible=%r)', hps_infeasible)
      return
    else:
      raise Error('Hyperparams are infeasible: %s', infeasible_reason)

  logger.info('Starting training.')
  if tuner:
    logger.info('Using tuner: loaded HParams from Vizier')
  else:
    logger.info('No tuner: using default HParams')
  logger.info('experiment_proto: %s', experiment_proto)
  logger.info('train_dir: %s', train_dir)
  logger.info('train_input_paths[0]: %s', train_input_paths[0])
  logger.info('val_input_paths[0]: %s', val_input_paths[0])
  logger.info('%r', list(hps.values()))
  generationinfo.to_file(os.path.join(train_dir, 'geninfo.pbtxt'))
  with gfile.Open(os.path.join(train_dir, config.hparams_name), 'w') as f:
    f.write(str(hps.to_proto()))

  eval_size = hps.eval_size or None

  def make_subdir(subdirectory_mame):
    path = os.path.join(train_dir, subdirectory_mame)
    gfile.MakeDirs(path)
    return path

  logger.info('Computing preprocessing statistics')
  # TODO(shoyer): move this over into preprocessing instead?
  experiment_proto = dataset_stats.compute_experiment_statistics(
      experiment_proto,
      train_input_paths,
      os.path.join(
          hps.input_dir,
          six.ensure_str(
              config.wetlab_experiment_train_pbtxt_path[hps.val_fold]) +
          '.wstats'),
      preprocess_mode=hps.preprocess_mode,
      max_size=eval_size,
      logdir=make_subdir('compute-statistics'),
      save_stats=hps.save_stats)

  logging.info('Saving experiment proto with statistics')
  with gfile.Open(
      os.path.join(train_dir, config.wetlab_experiment_train_name), 'w') as f:
    f.write(str(experiment_proto))

  logger.debug(str(hps.to_proto()))
  logger.debug(hps.run_name)

  tr_entries = len(sstable.MergedSSTable(train_input_paths))
  logger.info('Training sstable size: %d', tr_entries)
  val_entries = len(sstable.MergedSSTable(val_input_paths))
  logger.info('Validation sstable size: %d', val_entries)

  epoch_size = hps.epoch_size or int(tr_entries * (1 + hps.ratio_random_dna))
  num_batches_per_epoch = int(float(epoch_size) / hps.mbsz)

  eval_ff.config_pandas_display(FLAGS.interactive_display)
  tr_evaluator = eval_ff.Evaluator(
      hps,
      experiment_proto,
      train_input_paths,
      make_subdir(config.experiment_training_dir),
      verbose=FLAGS.verbose_eval)
  val_evaluator = eval_ff.Evaluator(
      hps,
      experiment_proto,
      val_input_paths,
      make_subdir(config.experiment_validation_dir),
      verbose=FLAGS.verbose_eval)

  with tf.Graph().as_default():
    # we need to use the registered key 'hparams'
    tf.add_to_collection('hparams', hps)

    # TODO(shoyer): collect these into a Model class:
    dummy_inputs = data.dummy_inputs(
        experiment_proto,
        input_features=hps.input_features,
        kmer_k_max=hps.kmer_k_max,
        additional_output=six.ensure_str(hps.additional_output).split(','))
    output_layer = output_layers.create_output_layer(experiment_proto, hps)
    net = ff.FeedForward(dummy_inputs, output_layer.logit_axis, hps)

    trainer = FeedForwardTrainer(hps, net, output_layer, experiment_proto,
                                 train_input_paths)

    summary_writer = tf.SummaryWriter(make_subdir('training'), flush_secs=30)

    # TODO(shoyer): file a bug to figure out why write_version=2 (now the
    # default) doesn't work.
    saver = tf.Saver(write_version=1)

    # We are always the chief since we do not do distributed training.
    # Every replica with a different task id is completely independent and all
    # must be their own chief.
    sv = tf.Supervisor(
        logdir=train_dir,
        is_chief=True,
        summary_writer=summary_writer,
        save_summaries_secs=10,
        save_model_secs=180,
        saver=saver)

    logger.info('Preparing session')

    train_report_dir = os.path.join(train_dir, config.experiment_training_dir)
    cur_train_report = os.path.join(train_report_dir,
                                    config.experiment_report_name)
    best_train_report = os.path.join(train_report_dir,
                                     config.experiment_best_report_name)

    valid_report_dir = os.path.join(train_dir, config.experiment_validation_dir)
    cur_valid_report = os.path.join(valid_report_dir,
                                    config.experiment_report_name)
    best_valid_report = os.path.join(valid_report_dir,
                                     config.experiment_best_report_name)

    best_checkpoint = os.path.join(train_dir, 'model.ckpt-lowest_val_loss')
    best_checkpoint_meta = best_checkpoint + '.meta'
    best_epoch_file = os.path.join(train_dir, 'best_epoch.txt')

    with sv.managed_session(master) as sess:

      logger.info('Starting queue runners')
      sv.start_queue_runners(sess)

      def save_and_evaluate():
        """Save and evaluate the current model.

        Returns:
          path: the path string to the checkpoint.
          summary_df: pandas.DataFrame storing the evaluation result on the
            validation dataset with rows for each output name and columns for
            each metric value
        """
        logger.info('Saving model checkpoint')
        path = sv.saver.save(
            sess,
            sv.save_path,
            global_step=sv.global_step,
            write_meta_graph=True)
        tr_evaluator.run(path, eval_size)
        summary_df, _ = val_evaluator.run_and_report(
            tuner,
            path,
            eval_size,
            metrics_targets=metrics_targets,
            metrics_measures=metrics_measures)
        return path, summary_df

def run_training_with_default_inputs(hps,
                                     train_dir,
                                     tuner=None,
                                     master='',
                                     val_fold_template='',
                                     metrics_targets=None,
                                     metrics_measures=None):
  """Start a training run with default inputs.

  Args:
    hps: tf.HParams with training parameters.
    train_dir: str path to train directory.
    tuner: optional hp_tuner.HPTuner.
    master: optional string to pass to a tf.Supervisor.
    val_fold_template: optional string to use to change the name of the
      validation fold data from its default.
    metrics_targets: String list of network targets to report metrics for.
    metrics_measures: Measurements about the performance of the network to
        report, e.g. 'auc/top_1p'.

  Raises:
    ValueError: Proto inconsistent with input feature.

  Returns:
    None.
  """
  gfile.MakeDirs(train_dir)

  task_log_path = os.path.join(train_dir, 'train_feedforward.log')
  io_utils.log_to_stderr_and_file(
      task_log_path, loggers=[logger, eval_ff.logger])

  logger.info('Setting up fold')
  experiment_proto, train_input_paths, val_input_paths = _setup_fold(
      hps.input_dir, train_dir, hps.val_fold, val_fold_template)

  if hps.additional_output:
    existing_ao = [ao.name for ao in experiment_proto.additional_output]
    for idx, name in enumerate(
        six.ensure_str(hps.additional_output).split(',')):
      if name not in existing_ao and name:
        experiment_proto.additional_output.add(
            name=name,
            measurement_id=idx)
  if data.STRUCTURE_PARTITION_FUNCTION in hps.input_features:
    if not experiment_proto.has_partition_function:
      raise ValueError(
          'invalid input_feature for proto lacking partition function: %s' %
          (data.STRUCTURE_PARTITION_FUNCTION))

  try:
    run_training(
        hps,
        experiment_proto,
        train_dir,
        train_input_paths,
        val_input_paths,
        tuner=tuner,
        master=master,
        metrics_targets=metrics_targets,
        metrics_measures=metrics_measures)
  except Exception:  # pylint: disable=broad-except
    # ensure errors end up in the logs
    logger.exception('Error encountered in run_training:')
    # re-raise to fail the task
    raise